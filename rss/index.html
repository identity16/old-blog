<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Identity16]]></title><description><![CDATA[Unidentified Written Posts..]]></description><link>http://localhost:2368/</link><image><url>http://localhost:2368/favicon.png</url><title>Identity16</title><link>http://localhost:2368/</link></image><generator>Ghost 2.9</generator><lastBuildDate>Thu, 17 Jan 2019 14:07:40 GMT</lastBuildDate><atom:link href="http://localhost:2368/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Direction aware hover pure CSS - Codepen.io 클론 코딩]]></title><description><![CDATA[<p><a href="https://codepen.io/2013/popular/pens/">Codepen.io-The Most Hearted of 2013</a> - <strong>100.</strong> <a href="https://codepen.io/FWeinb/pen/GrpqB">Direction aware hover pure CSS</a></p><p> 이번 펜은 마우스가 올라올 때 들어온 방향을 감지하는 Element를 JS 없이 CSS로만 구현하였다. 아래는 Codepen에 올라온 원본이다.</p><p data-height="438" data-theme-id="0" data-slug-hash="GrpqB" data-default-tab="result" data-user="FWeinb" data-pen-title="Direction aware hover pure CSS" style="height: 438px; box-sizing: border-box; display: flex; align-items: center; justify-content: center; border: 2px solid black; margin: 1em 0; padding: 1em;" class="codepen"><span>See the Pen <a href="https://codepen.io/FWeinb/pen/GrpqB/">Direction aware hover pure CSS</a> by Fabrice Weinberg (<a href="https://codepen.io/FWeinb">@FWeinb</a>) on <a href="https://codepen.io">CodePen</a>.</span></p>
<script async src="https://static.codepen.io/assets/embed/ei.js"></script><p></p><h2 id="-">코드 파악</h2><p>우선 어떤 원리인지 파악하기</p>]]></description><link>http://localhost:2368/direction-aware-hover-pure-css-codepen-io-keulron-koding/</link><guid isPermaLink="false">5c3ebb96f8108f1139c59c5b</guid><category><![CDATA[clone coding]]></category><category><![CDATA[codepen]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Thu, 17 Jan 2019 14:03:59 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/-----------2019-01-17------11.05.36.png" medium="image"/><content:encoded><![CDATA[<img src="http://localhost:2368/content/images/2019/01/-----------2019-01-17------11.05.36.png" alt="Direction aware hover pure CSS - Codepen.io 클론 코딩"><p><a href="https://codepen.io/2013/popular/pens/">Codepen.io-The Most Hearted of 2013</a> - <strong>100.</strong> <a href="https://codepen.io/FWeinb/pen/GrpqB">Direction aware hover pure CSS</a></p><p> 이번 펜은 마우스가 올라올 때 들어온 방향을 감지하는 Element를 JS 없이 CSS로만 구현하였다. 아래는 Codepen에 올라온 원본이다.</p><p data-height="438" data-theme-id="0" data-slug-hash="GrpqB" data-default-tab="result" data-user="FWeinb" data-pen-title="Direction aware hover pure CSS" style="height: 438px; box-sizing: border-box; display: flex; align-items: center; justify-content: center; border: 2px solid black; margin: 1em 0; padding: 1em;" class="codepen"><span>See the Pen <a href="https://codepen.io/FWeinb/pen/GrpqB/">Direction aware hover pure CSS</a> by Fabrice Weinberg (<a href="https://codepen.io/FWeinb">@FWeinb</a>) on <a href="https://codepen.io">CodePen</a>.</span></p>
<script async src="https://static.codepen.io/assets/embed/ei.js"></script><p></p><h2 id="-">코드 파악</h2><p>우선 어떤 원리인지 파악하기 위해 최종 결과 창에서 개발자도구로 살펴보았다.</p>
<p><img src="http://localhost:2368/content/images/2019/01/-----------2019-01-17------5.37.48.png" alt="Direction aware hover pure CSS - Codepen.io 클론 코딩"></p>
<p>대략적인 원리는 저런 마름모 4개가 있고 저 중에서 처음 마우스가 Hover된 것을 기준으로 방향을 판단하는 것으로 보인다. 이제 코드를 보자.</p>
<pre><code class="language-html">&lt;div class=&quot;box&quot;&gt;
    &lt;div class=&quot;box__right&quot;&gt;Right → Left&lt;/div&gt;
    &lt;div class=&quot;box__left&quot;&gt;Left → Right&lt;/div&gt;
    &lt;div class=&quot;box__top&quot;&gt;Top → Bottom&lt;/div&gt;
    &lt;div class=&quot;box__bottom&quot;&gt;Bottom → Top&lt;/div&gt;
    &lt;div class=&quot;box__center&quot;&gt;
      Hover from any side  
    &lt;/div&gt;
&lt;/div&gt;
</code></pre>
<p>HTML은 크게 <code>.box</code> 하나와 그 안에 각 방향에 따른 <code>div</code>와 중앙 <code>div</code>가 존재한다. 여기서 잠깐 의문을 가진 것이 왜 마름모에 대한 Element가 없는지인데, 위의 이미지에서 마름모는 <code>.box_left::before</code>라는 것을 가리켰다. 검색해보니 <code>::before</code>는 CSS 상에서 생성하는 가상요소였다. 그래서 HTML에서 나타나지 않은 것이었다.</p>
<p>일단 이정도면 &quot;마름모로 Hover 감지영역을 만들고 Hover가 되면 해당하는 방향으로 transform한다.&quot; 정도로 파악되었고 CSS는 막힐 때 참고용으로 보기로 하고 코딩에 들어갔다.</p>
<h2 id="--1">결과</h2><p>Source Code : <a href="https://github.com/identity16/codepen-io-clone-coding/tree/gh-pages/2013-100">https://github.com/identity16/codepen-io-clone-coding/tree/gh-pages/2013-100</a></p><p>Result : <a href="https://identity16.github.io/codepen-io-clone-coding/2013-100/">https://identity16.github.io/codepen-io-clone-coding/2013-100/</a></p><p> 아직은 CSS 자체에 미숙한 점이 많아 ::before이나 transform을 사용하는 부분에서 계속 참고하다보니 기존 코드를 많이 벗어나지 못한 느낌이 들었다. 계속 연습하면서 나만의 스타일로 코드 짜는 것을 익혀야할 것 같다.</p><h2 id="--2">응용</h2><p> 이것을 구현하면서 생각난 나중에 연습해볼 만한 것을 정리해 보았다. 이것들은 2013년 펜들을 한 번씩 코딩해보고 시간이 지난 후에 레벨 2 느낌으로 도전해보려고 한다.</p><ul><li>들어온 방향 뿐만 아니라 나가는 방향도 감지(간단한 게임으로도 응용 가능)</li><li>빠르게 여러 방향을 왔다갔다 했을 때의 딜레이 해결(아래 gif 참고)</li></ul><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2019/01/out.gif" class="kg-image" alt="Direction aware hover pure CSS - Codepen.io 클론 코딩"><figcaption>한 번 발견했더니 계속 거슬리는 딜레이..</figcaption></figure>]]></content:encoded></item><item><title><![CDATA[Preface - Codepen.io 클론 코딩]]></title><description><![CDATA[<p><a href="https://codepen.io">Codepen.io</a>라는 사이트는 "Front End Developer Playground &amp; Code Editor in the Browser"라는 소개글 자체로 알 수 있듯, 다양한 프론트엔드 코드들을 공유하고 갖고놀 수 있는 공간이다.</p><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2019/01/-----------2019-01-16------1.06.28.png" class="kg-image"><figcaption>Codepen.io 메인 페이지</figcaption></figure><p> 공유된 코드들은 신기한 것들이 많아 한 번씩 들어가보곤 한다. 그러던 와중에 <a href="https://codepen.io/2018/popular/pens/">The Most Hearted of 2018</a>이라는 페이지를</p>]]></description><link>http://localhost:2368/preface-codepen-io-keulron-koding/</link><guid isPermaLink="false">5c3eabb2f8108f1139c59c2e</guid><category><![CDATA[clone coding]]></category><category><![CDATA[codepen]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Wed, 16 Jan 2019 04:37:04 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/-----------2019-01-16------1.20.56.png" medium="image"/><content:encoded><![CDATA[<img src="http://localhost:2368/content/images/2019/01/-----------2019-01-16------1.20.56.png" alt="Preface - Codepen.io 클론 코딩"><p><a href="https://codepen.io">Codepen.io</a>라는 사이트는 "Front End Developer Playground &amp; Code Editor in the Browser"라는 소개글 자체로 알 수 있듯, 다양한 프론트엔드 코드들을 공유하고 갖고놀 수 있는 공간이다.</p><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2019/01/-----------2019-01-16------1.06.28.png" class="kg-image" alt="Preface - Codepen.io 클론 코딩"><figcaption>Codepen.io 메인 페이지</figcaption></figure><p> 공유된 코드들은 신기한 것들이 많아 한 번씩 들어가보곤 한다. 그러던 와중에 <a href="https://codepen.io/2018/popular/pens/">The Most Hearted of 2018</a>이라는 페이지를 발견했는데, 한 해동안 가장 인기있었던 펜(공유된 코드들을 펜이라 부름) 100개를 소개해주었다. URL의 연도를 계속 바꿔본 결과 2013년도부터 매년 소개했던 것 같다. 그래서 공부도 할 겸 여기에 있는 펜들 중 공부하기에 의미있을 법 한 것을 골라서 클론 코딩을 하며 배우고 그 점을 블로그에 공유해보자 한다. 최근 코드는 대부분 화려한 애니메이션, 신기한 특성 등을 다룬 것이 많고 오히려 2013년도 펜들이 단순하고 실용적인 것들이 많아 학생인 내가 공부하기에는 더 적절한 것 같아서 <a href="https://codepen.io/2013/popular/pens/">The Most Hearted of 2013</a>부터 시작하고 점차 최근으로 넘어갈 예정이다.</p><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2019/01/-----------2019-01-16------1.19.18.png" class="kg-image" alt="Preface - Codepen.io 클론 코딩"><figcaption>The Most Hearted of 2013</figcaption></figure>]]></content:encoded></item><item><title><![CDATA[5.3 The Basics of Caches]]></title><description><![CDATA[<h1 id="thebasicsofcaches">The Basics of Caches</h1>
<h2 id="questions">Questions</h2>
<ol>
<li>데이터가 존재하는지 어떻게 확인?</li>
<li>우리가 어디를 보고 어디에 넣어?
<ol>
<li>Directed-mapped</li>
<li>Fully associative</li>
<li>M-way Set associative</li>
</ol>
</li>
</ol>
<h2 id="directivemappedcache">Directive Mapped Cache</h2>
<ul>
<li>위치가 주소에 의해 결정됨</li>
<li>나머지 연산을 이용해 캐시 주소 결정
<ul>
<li>(주소) % (캐시 블럭 수)</li>
<li>캐시 블럭 수는 2의 거듭제곱이다.</li>
<li>주소 하위 비트 사용</li>
</ul>
</li>
</ul>
<h2 id="tagsandvalidbits">Tags and Valid Bits</h2>]]></description><link>http://localhost:2368/5-3-the-basics-of-caches/</link><guid isPermaLink="false">5c35fbb82d91b6c5113154e2</guid><category><![CDATA[computer-architecture]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Fri, 21 Dec 2018 01:45:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/anatomy-1751201_1280.png" medium="image"/><content:encoded><![CDATA[<h1 id="thebasicsofcaches">The Basics of Caches</h1>
<h2 id="questions">Questions</h2>
<ol>
<li>데이터가 존재하는지 어떻게 확인?</li>
<li>우리가 어디를 보고 어디에 넣어?
<ol>
<li>Directed-mapped</li>
<li>Fully associative</li>
<li>M-way Set associative</li>
</ol>
</li>
</ol>
<h2 id="directivemappedcache">Directive Mapped Cache</h2>
<ul>
<li>위치가 주소에 의해 결정됨</li>
<li>나머지 연산을 이용해 캐시 주소 결정
<ul>
<li>(주소) % (캐시 블럭 수)</li>
<li>캐시 블럭 수는 2의 거듭제곱이다.</li>
<li>주소 하위 비트 사용</li>
</ul>
</li>
</ul>
<h2 id="tagsandvalidbits">Tags and Valid Bits</h2>
<ul>
<li>어떤 블럭이 캐시에 있는지 알 수 있을까?
<ul>
<li>블럭 주소도 저장해놓는다.</li>
<li>상위 비트를 저장 =&gt; 태그</li>
</ul>
</li>
<li>데이터가 아예 없다면?
<ul>
<li>Valid bit로 표시</li>
<li>1 = 있, 0 = 없 (초기값 0)</li>
</ul>
</li>
</ul>
]]></content:encoded></item><item><title><![CDATA[5.2 Memory Technologies]]></title><description><![CDATA[<h1 id="memorytechnologies">Memory Technologies</h1>
<p>(시간이 급한 관계로 몇 가지만 추려서 정리했습니다.)</p>
<h2 id="memorytechnology">Memory Technology</h2>
<p>  대표적인 메모리의 종류는 아래와 같다.</p>
<ul>
<li><strong>Static RAM(SRAM)</strong></li>
<li><strong>Dynamic RAM(DRAM)</strong></li>
<li><strong>Magnetic Disk</strong></li>
</ul>
<p>  SRAM -&gt; DRAM -&gt; Magnetic Disk로 갈수록 접근 속도가 100배 빨라지고 GB 당 가격이 100 배 낮아진다.</p>
<p>빠른 메모리는 비싸기 때문에 이들을 적절히 혼용하여</p>]]></description><link>http://localhost:2368/5-2-memory-technologies/</link><guid isPermaLink="false">5c35fbe52d91b6c5113154e7</guid><category><![CDATA[computer-architecture]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Thu, 20 Dec 2018 17:39:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/hard-disk-775847_1280.jpg" medium="image"/><content:encoded><![CDATA[<h1 id="memorytechnologies">Memory Technologies</h1>
<img src="http://localhost:2368/content/images/2019/01/hard-disk-775847_1280.jpg" alt="5.2 Memory Technologies"><p>(시간이 급한 관계로 몇 가지만 추려서 정리했습니다.)</p>
<h2 id="memorytechnology">Memory Technology</h2>
<p>  대표적인 메모리의 종류는 아래와 같다.</p>
<ul>
<li><strong>Static RAM(SRAM)</strong></li>
<li><strong>Dynamic RAM(DRAM)</strong></li>
<li><strong>Magnetic Disk</strong></li>
</ul>
<p>  SRAM -&gt; DRAM -&gt; Magnetic Disk로 갈수록 접근 속도가 100배 빨라지고 GB 당 가격이 100 배 낮아진다.</p>
<p>빠른 메모리는 비싸기 때문에 이들을 적절히 혼용하여 가능한 빠른 성능을 내는 것이 최상의 선택이다.</p>
<h3 id="sramtechnology">SRAM Technology</h3>
<p> 6 ~ 8 개의 트랜지스터를 사용하여 데이터를 저장한다.</p>
<ul>
<li>빠르지만 비쌈</li>
<li>접근 시간이 일정</li>
<li>Refresh 될 필요 없음</li>
<li>캐시 메모리로 많이 사용됨</li>
</ul>
<h3 id="dramtechnology">DRAM Technology</h3>
<p>  데이터는 Capacitor의 Charge로 저장됨</p>
<ul>
<li>주기적으로 Refresh 되어야 함
<ul>
<li>Read Contents and Write Back</li>
<li>Performed on a DRAM &quot;row&quot;</li>
</ul>
</li>
<li>Synchronous DRAM (SDRAM)
<ul>
<li>대역폭을 향상하기 위해 클럭 추가</li>
<li>Ex) Double Data Rate(DDR) DRAM : 클럭의 rising, falling edge에 데이터 전달</li>
</ul>
</li>
</ul>
<h3 id="flashstorage">Flash Storage</h3>
<ul>
<li>
<p>비휘발성 반도체 스토리지</p>
<ul>
<li>디스크보다 100 ~ 1000배 빠름</li>
<li>작고 저전력에 튼튼함</li>
<li>근데 비쌈</li>
</ul>
</li>
<li>
<p>종류</p>
<ul>
<li>NOR Flash</li>
<li>NAND Flash</li>
</ul>
</li>
<li>
<p>Flash bit는 1000번 이상 접근하면 닳는다.</p>
<ul>
<li>Wear Leveling으로 최대한 고르게 사용하도록 한다.</li>
</ul>
</li>
</ul>
<h3 id="diskmemory">Disk Memory</h3>
<ul>
<li>
<p>부분 명칭 : Cylinder, Sector, Track, Disk Platters</p>
</li>
<li>
<p>각각의 섹터에는..</p>
<ul>
<li>Sector ID</li>
<li>Data</li>
<li>Error Correcting Code(ECC)</li>
<li>Synchronization Fields and Gaps</li>
</ul>
</li>
<li>
<p>Sector에 접근하기 위해서..</p>
<ul>
<li>다른 접근들은 큐에 대기시킴</li>
<li>Seek : 트랙을 찾기 위해 헤드를 움직임</li>
<li>Rotational Latency : 회전하는데 걸리는 시간</li>
<li>Data Transfer : 데이터 전달</li>
<li>Controller Overhead</li>
</ul>
</li>
<li>
<p>평균 Read Time 계산</p>
<ul>
<li>평균 Seek Time + 평균 Rotational Latency + Transfer Time + Controller Delay</li>
<li>강의 자료 13 참고</li>
</ul>
</li>
</ul>
<h3 id="diskperformanceissues">Disk Performance Issues</h3>
<ul>
<li>제조업체는 평균 Seek Time을 알려준다.</li>
<li>Disk Drive는 캐시를 포함한다.</li>
</ul>
]]></content:encoded></item><item><title><![CDATA[5.1 Introduction]]></title><description><![CDATA[<h1 id="introduction">Introduction</h1>
<p>(시간이 급한 관계로 몇 가지만 추려서 정리했습니다.)</p>
<h2 id="principleoflocality">Principle of Locality</h2>
<p>  프로그램은 한 번에 작은 비율의 주소 공간에 접근한다. 그래서 다시 접근할 확률이 높은 것들에 대한 원칙을 정의하여 효율적으로 공간을 사용하는 것이 좋다.</p>
<h3 id="temporallocalitytime">Temporal Locality(Time)</h3>
<ul>
<li>최근에 접근한 것들은 머지않아 다시 접근할 확률이 높다.</li>
</ul>
<h3 id="spatiallocalityspace">Spatial Locality(Space)</h3>
<ul>
<li>최근에 접근한 것과</li></ul>]]></description><link>http://localhost:2368/5-1-introduction/</link><guid isPermaLink="false">5c35fc802d91b6c5113154ed</guid><category><![CDATA[computer-architecture]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Thu, 20 Dec 2018 16:57:00 GMT</pubDate><content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<p>(시간이 급한 관계로 몇 가지만 추려서 정리했습니다.)</p>
<h2 id="principleoflocality">Principle of Locality</h2>
<p>  프로그램은 한 번에 작은 비율의 주소 공간에 접근한다. 그래서 다시 접근할 확률이 높은 것들에 대한 원칙을 정의하여 효율적으로 공간을 사용하는 것이 좋다.</p>
<h3 id="temporallocalitytime">Temporal Locality(Time)</h3>
<ul>
<li>최근에 접근한 것들은 머지않아 다시 접근할 확률이 높다.</li>
</ul>
<h3 id="spatiallocalityspace">Spatial Locality(Space)</h3>
<ul>
<li>최근에 접근한 것과 가까이 위치한 것이 다음에 접근할 확률이 높다.</li>
</ul>
]]></content:encoded></item><item><title><![CDATA[3.4 Conditioning on Event]]></title><description><![CDATA[<h1 id="conditioningonevent">Conditioning on Event</h1>
<p>  여기도 역시 Conditioning, 어떤 Event가 발생했을 때의 상황을 고려한 확률을 생각해볼 수 있다. 어떤 Event A가 발생한 조건에서 Continuous Random Variable $ X $의 PDF는 다음을 만족한다.</p>
<p>$$ P(X\in B \vert A) = \displaystyle\int_B f_{X\vert A}(x)dx $$</p>
<p>  만약 $ A $가 $ P(X \in</p>]]></description><link>http://localhost:2368/3-4-conditioning-on-event/</link><guid isPermaLink="false">5c35fcba2d91b6c5113154f2</guid><category><![CDATA[probability-and-statistics]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Sun, 16 Dec 2018 05:34:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/chart-2785917_1280.jpg" medium="image"/><content:encoded><![CDATA[<h1 id="conditioningonevent">Conditioning on Event</h1>
<img src="http://localhost:2368/content/images/2019/01/chart-2785917_1280.jpg" alt="3.4 Conditioning on Event"><p>  여기도 역시 Conditioning, 어떤 Event가 발생했을 때의 상황을 고려한 확률을 생각해볼 수 있다. 어떤 Event A가 발생한 조건에서 Continuous Random Variable $ X $의 PDF는 다음을 만족한다.</p>
<p>$$ P(X\in B \vert A) = \displaystyle\int_B f_{X\vert A}(x)dx $$</p>
<p>  만약 $ A $가 $ P(X \in A) &gt; 0 $인 실수 집합이면,</p>
<p>$$ f_{X\vert A}(x) = \begin{cases} \frac{f_X(x)}{P(X\in A)}\ \ \ \ if\ x\in A \\0\ \ \ \ \ \ \ \ \ \ \  \ \ \ otherwise \end{cases} $$</p>
<h2 id="conditionalexpectation">Conditional Expectation</h2>
<p>  이번에는 기대값이다. 위와 같은 조건에서 기대값은 아래와 같이 정의된다.</p>
<p>$$ E[X\vert  A] = \displaystyle \int^{\infty}_{-\infty}xf_{X\vert A}(x)dx $$</p>
<p>  2.6장에서 다룬 &quot;Conditional Expectation&quot;의 내용들이 여기서도 유효하다. 따라서 아래 식도 성립한다.</p>
<p>$$ E[g(X)\vert A] = \displaystyle \int^{\infty}_{-\infty}g(x)f_{X\vert A}(x)dx $$</p>
<h2 id="versionoftotalprobabilitytheorem">Version of Total Probability Theorem</h2>
<p>  $ A_1, \cdots, A_n $이 서로 disjoint하고 각각의 $ i $에 대해 $ P(A_i) &gt; 0 $이면서 Sample Space의 Partition이라고 하자. 그러면 아래 식이 성립한다.</p>
<p>$$ f_X(x) = \displaystyle \sum^n_{i=1} P(A_i)f_{X\vert A_i}(x) $$</p>
<p>  이 식은 Total Probability Theorem을 이용해 $ P(X\le x) $를 구하는 식을 변형하여 증명할 수 있다.</p>
]]></content:encoded></item><item><title><![CDATA[3.3 Normal Random Variables]]></title><description><![CDATA[<h1 id="normalrandomvariable">Normal Random Variable</h1>
<p>  Normal Random Variable의 PDF 그래프는 고등학교 때 한번쯤 봤을 법한 정규분포곡선이다.</p>
<p>$$ f_X(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-(x-\mu)^2/2\sigma^2} $$</p>
<p>$$ E[X] = \mu $$</p>
<p>$$ var(X) = \sigma ^2 $$</p>
<p>$ \mu, \sigma $는 각각 평균과 표준편차를 나타내는 기호이다.</p>
<h2 id="properties">Properties</h2>
<p>  Normal Random Variable은</p>]]></description><link>http://localhost:2368/3-3-normal-random-variables/</link><guid isPermaLink="false">5c35fd0f2d91b6c5113154fb</guid><category><![CDATA[probability-and-statistics]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Sun, 16 Dec 2018 04:54:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/analytics-2158454_1280.png" medium="image"/><content:encoded><![CDATA[<h1 id="normalrandomvariable">Normal Random Variable</h1>
<img src="http://localhost:2368/content/images/2019/01/analytics-2158454_1280.png" alt="3.3 Normal Random Variables"><p>  Normal Random Variable의 PDF 그래프는 고등학교 때 한번쯤 봤을 법한 정규분포곡선이다.</p>
<p>$$ f_X(x) = \frac{1}{\sqrt{2\pi}\sigma}e^{-(x-\mu)^2/2\sigma^2} $$</p>
<p>$$ E[X] = \mu $$</p>
<p>$$ var(X) = \sigma ^2 $$</p>
<p>$ \mu, \sigma $는 각각 평균과 표준편차를 나타내는 기호이다.</p>
<h2 id="properties">Properties</h2>
<p>  Normal Random Variable은 여러가지 특성을 가지고 있다. 물론 이것들도 대부분 고등학교 때 본 기억이 있을 것이다. 하나씩 살펴보자</p>
<h3 id="property1symmetry">Property 1: Symmetry</h3>
<p>  확률 분포가 흔히 종모양 곡선을 그리며, 평균값을 기준으로  대칭을 이룬다. 예를 들어 $ \mu = 1 $인 Normal Random Variable이 있다고 하자. 이런 경우에는 1을 기준으로 확률 분포가 대칭이므로 $ P(x &lt; 0) = P(x &gt; 2) $ 이다. 뿐만 아니라 $ P(x \lt \mu) = P(x \gt \mu) = 0.5 $ 라는 사실도 대칭성에 의해 알 수 있다.</p>
<h3 id="property2normalityispreservedbylineartransformations">Property 2: Normality is Preserved by Linear Transformations</h3>
<p> $ X $가 Normal Random Variable일때 $ Y = aX + b $인 Random Variable $ Y $도 여전히 Normal이고 $ X $의 평균과 분산이 각각  $ \mu, \sigma^2 $라 할 때 Y의 평균과 분산은 각각 아래와 같다.</p>
<p>$$ E[Y] = a\mu + b $$</p>
<p>$$ var(Y) = a^2\sigma^2 $$</p>
<h3 id="property3standardnormalrandomvariable">Property 3: Standard Normal Random Variable</h3>
<p>  Standard Normal Random Variable이란 $ \mu = 0, \sigma^2 = 1$인 Normal Random Variable인데, 고등학교 때의 표준정규분포에 해당한다고 생각하면 된다.</p>
<h4 id="standardization">Standardization</h4>
<p>  일반적인 Normal Random Variable $ X $를 Standard인 Random Variable $ Y $로 만드려면 아래와 같이 표준화(Standardization)할 수 있다.</p>
<p>$$ Y = \frac{X - \mu}{\sigma} $$</p>
<h4 id="cdfofstandardnormalrandomvariable">CDF of Standard Normal Random Variable</h4>
<p> Standard Normal Random Variable의 PDF는 아래와 같다. ($ \mu = 0, \sigma^2 = 1 $)</p>
<p>$$ f_Y(y) = \frac{1}{\sqrt{2\pi}}e^{-y^2/2} $$</p>
<p>  이를 바탕으로 CDF를 만들면 아래와 같다. 이 함수는 $ \Phi $으로 표기한다.</p>
<p>$$ \Phi(y) = P(Y \le y) = P(Y \lt y) = \frac{1}{\sqrt{2\pi}}\int^{y}_{-\infty}e^{-t^2/2}dt $$</p>
<p>$ \Phi $는 우리가 계산하지는 않고 Standard Normal Table을 보며 $ \Phi(y) $의 값을 찾아서 사용하면 된다.</p>
]]></content:encoded></item><item><title><![CDATA[3.2 Cumulative Distribution Functions]]></title><description><![CDATA[<h1 id="cumulativedistributionfunctions">Cumulative Distribution Functions</h1>
<p>  연속적인 값에 대해, 우리는 $ P(X=x) $ 보다는 $ P(X \le x) $에 더 관심을 가지고 있다. PDF를 적분하면 그 값을 구할 수 있지만 $ f(x) = P(X \le x) $ 처럼 표현할 수 있는 함수가 있으면 더 편리할 것이다. 그런 함수가 Cumulative Distribution Function(CDF)이다. CDF는</p>]]></description><link>http://localhost:2368/3-2-cumulative-distribution-functions/</link><guid isPermaLink="false">5c35fd9f2d91b6c51131550a</guid><category><![CDATA[probability-and-statistics]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Sun, 16 Dec 2018 04:27:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/stones-1694879_1280.jpg" medium="image"/><content:encoded><![CDATA[<h1 id="cumulativedistributionfunctions">Cumulative Distribution Functions</h1>
<img src="http://localhost:2368/content/images/2019/01/stones-1694879_1280.jpg" alt="3.2 Cumulative Distribution Functions"><p>  연속적인 값에 대해, 우리는 $ P(X=x) $ 보다는 $ P(X \le x) $에 더 관심을 가지고 있다. PDF를 적분하면 그 값을 구할 수 있지만 $ f(x) = P(X \le x) $ 처럼 표현할 수 있는 함수가 있으면 더 편리할 것이다. 그런 함수가 Cumulative Distribution Function(CDF)이다. CDF는 연속적인 값 뿐만 아니라 이산적인 값에 대한 식도 포함하고 있다.</p>
<p>$$ F_X(x) = P(X \le x) = \begin{cases} \displaystyle\sum_{k \le x} p_X(k)\ \ \ \ \ \ \ X: discrete \\ \int^a_{-\infty}f_X(t)\ \ \ \ \ \ X: continuous \end{cases} $$</p>
<p>  CDF는 0부터 1까지 증가하는 형태의 그래프로 표현된다. 랜덤 변수가 이산적인 값일 때는 계단형 그래프가 나올 것이고, 연속적일 때는 서서히 증가할 것이다.</p>
<h2 id="propertiesofthecdfs">Properties of the CDFs</h2>
<p>  이제 CDF의 특성을 소개할 건데, Random Variable 종류에 따라 나누어 설명하겠다.</p>
<h3 id="discretervpropertiesofthecdfs">Discrete RV: Properties of the CDFs</h3>
<ul>
<li>
<p><strong>CDF의 형태</strong></p>
<p>$$ F_X(k) = \displaystyle \sum^{k}_{i=-\infty} P(X = k) $$</p>
</li>
<li>
<p><strong>CDF로부터 PMF를 구하는 법</strong></p>
<p>$$ P(X=k) = F_{X}(k) - F_{X}(k-1) $$</p>
</li>
</ul>
<h3 id="continuousrvpropertiesofthecdfs">Continuous RV: Properties of the CDFs</h3>
<ul>
<li>
<p><strong>CDF의 형태</strong></p>
<p>$$ F_X(x) = \displaystyle \int^{x}_{-\infty} f_X(y)dy $$</p>
</li>
<li>
<p><strong>CDF로부터 PDF를 구하는 법</strong> : CDF를 미분</p>
<p>$$ f_X(x) = \frac{dF_X(x)}{dx} $$</p>
</li>
</ul>
]]></content:encoded></item><item><title><![CDATA[3.1 Continuous Random Variables and PDFs]]></title><description><![CDATA[<h1 id="continuousrandomvariablesandpdfs">Continuous Random Variables and PDFs</h1>
<p>  지금까지 우리는 이산적인 값에 대한 확률을 다루었다. 여기서는 연속적인 값에 대한 새로운 Random Variable과 Probability Density Function(PDF)를 소개하겠다.</p>
<h2 id="continuousrandomvariables">Continuous Random Variables</h2>
<p>  Continuous Random Variable은 연속적인 값을 다루기 위한 것이며 다음과 같은 특징이 있다.</p>
<ul>
<li>무한한 범위에서 정의되어있다.</li>
<li>어떤 값 $ X=x $에 대하여, $ P(</li></ul>]]></description><link>http://localhost:2368/3-1-continuous-random-variables-and-pdfs/</link><guid isPermaLink="false">5c35fde72d91b6c511315511</guid><category><![CDATA[probability-and-statistics]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Sun, 16 Dec 2018 04:00:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/black-and-white-2309273_1280.jpg" medium="image"/><content:encoded><![CDATA[<h1 id="continuousrandomvariablesandpdfs">Continuous Random Variables and PDFs</h1>
<img src="http://localhost:2368/content/images/2019/01/black-and-white-2309273_1280.jpg" alt="3.1 Continuous Random Variables and PDFs"><p>  지금까지 우리는 이산적인 값에 대한 확률을 다루었다. 여기서는 연속적인 값에 대한 새로운 Random Variable과 Probability Density Function(PDF)를 소개하겠다.</p>
<h2 id="continuousrandomvariables">Continuous Random Variables</h2>
<p>  Continuous Random Variable은 연속적인 값을 다루기 위한 것이며 다음과 같은 특징이 있다.</p>
<ul>
<li>무한한 범위에서 정의되어있다.</li>
<li>어떤 값 $ X=x $에 대하여, $ P(X=x) = 0 $이다.</li>
</ul>
<p>  이 변수의 값이 될 수 있는 경우는 버스가 도착하는 시간, 무작위로 선택된 사람의 키 등이 있다.</p>
<h2 id="probabilitydensityfunctionpdf">Probability Density Function(PDF)</h2>
<p>  Continuous Random Variable은 항상 $ P(X=x) = 0 $이기 때문에 PMF를 만드는 것은 실질적인 의미가 없다. PMF 대신 우리는 연속적이고 0 이상의 값을 가지는 Probability Density Function을 사용할 것이다. X에 대한 PDF는 $ f_X(x) $이라고 표기한다.</p>
<h3 id="intuition">Intuition</h3>
<p>  아래는 PDF에 대한 이해를 돕기 위한 내용들이다.</p>
<ul>
<li>$ f_X(a) $는 $ P(X=a) $가 아니다</li>
<li>$ P(X=a) = \int^a_a f_x(x) dx = 0 $
<ul>
<li>=&gt; $ P(X \le a) = P(X\lt a)+P(X=a) = P(X\lt A) $</li>
</ul>
</li>
<li>유효한 Probability Law는 $ P(\Omega) = 1 $과 $ P(A) \gt 0 $을 만족해야 한다고 했다. 이것은 PDF에도 비슷하게 적용된다.
<ul>
<li>Normalization, PDF 그래프의 총 밑넓이는 1이어야 한다.
<ul>
<li>$ \int^{\infty}_{-\infty}f_X(x) = P(-\infty &lt; X &lt; \infty) = 1 $</li>
</ul>
</li>
<li>$ f_X $의 값들은 0 이상이어야 한다.
<ul>
<li>$ P(x\in B) = \int_{x\in B}f_X(x)dx \ge 0 $, for all $ B $</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="propertiesofthepdf">Properties of the PDF</h3>
<p>  아래는 PDF의 특성을 정리한 것이다. 여기서 $ X $는 Continuous Random Variable이다.</p>
<ul>
<li>$ f_X(x) \ge 0,\ for\ all\ x $</li>
<li>$ \int^{\infty}_{-\infty}f_X(x)dx = 1 $</li>
<li>$ \delta $가 매우 작으면, $ P([x, x+\delta]) \approx f_X(x)\cdot \delta $</li>
<li>실수 전체의 부분집합 $ B $에 대해
<ul>
<li>$ P(X\in B) = \int_B f_X(x)dx $</li>
</ul>
</li>
</ul>
<h2 id="expectationofacontinuousrandomvariable">Expectation of A Continuous Random Variable</h2>
<p>  Continuous Random Variable의 기대값은 어떻게 구할까? 기존에 알고 있던 Random Variable들은 PMF를 사용해서 아래와 같이 Expectation을 구했다.</p>
<p>$$ E[X] = \displaystyle \sum_{x} xp_X(x) $$</p>
<p>  그렇지만 Continuous Random Variable은 PDF로 된 확률을 이용하고, 연속적인 값이기 때문에 $ \sum $ 대신 $ \int $를 이용하여 합친다.</p>
<p>$$ E[X] = \int^{\infty}_{-\infty} xf_X(x)dx $$</p>
<h2 id="varianceofacontinuousrandomvariable">Variance of A Continuous Random Variable</h2>
<p>  Continuous Random Variable이라고 해도 분산의 정의가 바뀌는 것은 아니기 때문에 앞에서 본 기대값을 적용만 하면 된다.</p>
<p>$$ var(X) = E[(X - E[X])^2] = \int^{\infty}_{-\infty} (x-E[X])^2f_X(x)dx $$</p>
<h2 id="exponentialrandomvariable">Exponential Random Variable</h2>
<p>  연속적인 값을 다루는 Random Variable인데 PDF의 형태가 지수함수이다.</p>
<p>$$ f_X(x) = \begin{cases} \lambda e^{-\lambda x}\ \ if\ x\ge 0 \\ 0\ \ \ \ \ \ \ \ \ otherwise \end{cases} $$</p>
<p>  기대값과 분산은 각각 아래와 같다.</p>
<p>$$ E[X] = \frac{1}{\lambda} $$</p>
<p>$$ var(X) = \frac{1}{\lambda^2} $$</p>
<p>  그리고 $X$가 어떤 값 이상일 때의 확률은 지수 형태로 나온다.</p>
<p>$$ P(X\ge a) = \int^{\infty}_{a} \lambda e^{-\lambda x} = -e^{-\lambda x} \bigg\rvert^{\infty}_a = e^{-\lambda a}$$</p>
]]></content:encoded></item><item><title><![CDATA[2.7 Independence]]></title><description><![CDATA[<h1 id="independence">Independence</h1>
<p>  Random Variable 간의 독립인 경우에 대해 다루며, 이 때 PMF, Expectation, Variance가 어떤 특성을 지니는지도 함께 살펴볼 것이다.</p>
<h2 id="independenceofrandomvariables">Independence of Random Variables</h2>
<p>  두 랜덤 변수 $ X, Y $가 독립이려면 PMF가 다음을 만족해야 한다.</p>
<p>$$ p_{X,Y}(x,y) = p_X(x)p_Y(y)\ for\ all\ x,y$$</p>
<p>  마치</p>]]></description><link>http://localhost:2368/2-7-independence/</link><guid isPermaLink="false">5c35fe742d91b6c51131551e</guid><category><![CDATA[probability-and-statistics]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Sat, 15 Dec 2018 06:35:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/buttes-chaumont-898675_1280.jpg" medium="image"/><content:encoded><![CDATA[<h1 id="independence">Independence</h1>
<img src="http://localhost:2368/content/images/2019/01/buttes-chaumont-898675_1280.jpg" alt="2.7 Independence"><p>  Random Variable 간의 독립인 경우에 대해 다루며, 이 때 PMF, Expectation, Variance가 어떤 특성을 지니는지도 함께 살펴볼 것이다.</p>
<h2 id="independenceofrandomvariables">Independence of Random Variables</h2>
<p>  두 랜덤 변수 $ X, Y $가 독립이려면 PMF가 다음을 만족해야 한다.</p>
<p>$$ p_{X,Y}(x,y) = p_X(x)p_Y(y)\ for\ all\ x,y$$</p>
<p>  마치 $ P(A\cap B) = P(A)P(B) $이면 두 Event가 독립인 것과 같은 이치이다. $ X,Y $가 서로의 확률에 영향을 미치지 않기 때문에 $ \{X=x \} $와 $\{Y=y\} $가 동시에 일어나는 경우의 확률은 각각의 확률을 곱한 것과 같다.</p>
<h2 id="expectationofindependentvariables">Expectation of Independent Variables</h2>
<p>  기대값을 계산할 때 1. ($ E[XY] = \displaystyle \sum_x \sum_y xyp_{X,Y}(x,y) $ 라는 사실)에 2.(위에 나온 식)과 3.(기대값의 선형성)을 적용하면 다음과 같은 식이 탄생한다.</p>
<p>$$ E[XY] = E[X]E[Y] $$</p>
<p>위에서 1, 2, 3으로 적용 순서까지 적어놓았으니 직접 전개해서 이 식을 증명해보도록 하자.</p>
<h2 id="varianceofindependentvariables">Variance of Independent Variables</h2>
<p>  독립인 두 랜덤 변수 $ X, Y $의 합 $ Z = X + Y $에 대해 다음 식이 성립한다.</p>
<p>$$ var(Z) = var(X) + var(Y) $$</p>
<p>  이것은 직관적이지 않으므로 증명을 한 번 해보자.</p>
<h3 id="proof">Proof</h3>
<p>$$ \begin{equation}var(Z) \\ = E[(X + Y - E[X + Y])^2] \\= E[(X + Y - E[X] - E[Y])^2] \\= E[((X - E[X]) + (Y - E[Y]))^2]  \\= E[(X - E[X])^2] + E[(Y - E[Y])^2] +2E[(X-E[X])(Y-E[Y])] \\= E[(X - E[X])^2] + E[(Y - E[Y])^2] \\= var(X) + var(Y) \end{equation} $$</p>
<p>  다섯 번째 줄에서 여섯 번째 줄로 넘어갈 때 $ 2E[(X-E[X])(Y-E[Y])] $가 사라졌는데, 이 값이 0이기 때문이다. 아래의 식을 보자. 참고로 $ X, Y $가 독립이므로 $ (X-E[X]) $ 와$ (Y-E[Y]) $도 독립이다.</p>
<p>$$ \begin{equation} E[(X-E[X])(Y-E[Y])]\\=E[X-E[X]]E[Y-E[Y]]\\=(E[X]-E[E[X]])(E[Y]-E[E[Y]])\\=(E[X]-E[X])(E[Y]-E[Y])\\=0 \end{equation} $$</p>
<p>여기까지, 2장이 전부 끝났다. 다음 포스팅부터는 3장에 들어갈 예정이다.</p>
]]></content:encoded></item><item><title><![CDATA[2.6 Conditioning]]></title><description><![CDATA[<h1 id="conditioning">Conditioning</h1>
<p>  이 부분의 내용은 Random Variable에 조건부 확률 개념을 더하는 것이라고 생각하면 된다. 그에 따른 PMF, Expectation의 변화를 알아보자.</p>
<h2 id="conditioningonrandomvariableonanevent">Conditioning on Random Variable on an Event</h2>
<p>  어떤 Event $ A $가 발생했을 때, Random Variable $ X $에 관한 PMF는 아래와 같다.</p>
<p>$$ p_{X\vert A}(x) = P(X=x \vert A)</p>]]></description><link>http://localhost:2368/2-6-conditioning/</link><guid isPermaLink="false">5c35fed02d91b6c511315528</guid><category><![CDATA[probability-and-statistics]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Sat, 15 Dec 2018 05:58:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/financial-2860753_1280.jpg" medium="image"/><content:encoded><![CDATA[<h1 id="conditioning">Conditioning</h1>
<img src="http://localhost:2368/content/images/2019/01/financial-2860753_1280.jpg" alt="2.6 Conditioning"><p>  이 부분의 내용은 Random Variable에 조건부 확률 개념을 더하는 것이라고 생각하면 된다. 그에 따른 PMF, Expectation의 변화를 알아보자.</p>
<h2 id="conditioningonrandomvariableonanevent">Conditioning on Random Variable on an Event</h2>
<p>  어떤 Event $ A $가 발생했을 때, Random Variable $ X $에 관한 PMF는 아래와 같다.</p>
<p>$$ p_{X\vert A}(x) = P(X=x \vert A) = \frac{P(\{X=x\} \cap A)}{P(A)} $$</p>
<p>  사실 기존 조건부 확률과 크게 다를 것은 없다. 단지 Event를 표현하는 방식에 $ \{X=x\} $가 추가되었을 뿐이다.</p>
<h2 id="conditioningonrandomvariableonanother">Conditioning on Random Variable on Another</h2>
<p>  이번에는 Event $ A $  대신 다른 Random Variable $ Y $에 대햐여 $ \{Y = y\} $ 일 때, Random Variable $ X $에 관한 PMF는 아래와 같다.</p>
<p>$$ p_{X\vert Y}(x\vert y) = P(X=x \vert Y=y) = \frac{p_{X,Y}(x, y)}{p_Y(y)} $$</p>
<p>$ A = \{Y=y\} $ 라고 생각하고 전개하면 된다. 둘 다 Random Variable이라서 마지막 수식은 Joint PMF와 PMF로 표현하였다.</p>
<h2 id="someusefulrules">Some Useful Rules</h2>
<p>  여기서 소개하는 것은 Conditional PMF의 정의를 이용한 응용식이다.</p>
<h3 id="calculatingthejointpmffromtheconditionalpmf">Calculating the Joint PMF from the conditional PMF</h3>
<p>  Conditional PMF로부터 Joint PMF를 구하는 식이다. 아마 이 식을 보면 조건부 확률에서 교집합의 확률을 구하는 식이 떠오를 것이다.</p>
<p>$$ p_{X,Y}(x,y) = p_Y(y)p_{X\vert Y}(x\vert y) $$</p>
<p>  이 식은 마치 조건부 확률에서의 $ P(A\cap B) = P(A)P(B\vert A) $와 유사하다.</p>
<h3 id="calculatingthemarginalpmffromtheconditionalpmf">Calculating the marginal PMF from the conditional PMF</h3>
<p>  이번에는 Joint PMF가 아니라 Marginal PMF를 구하는 식이다.</p>
<p>$$ p_X(x) = \displaystyle \sum_y p_Y(y)p_{X\vert Y}(x\vert y) $$</p>
<p>  이것은 Total Probability Theorem과 유사하다.</p>
<h2 id="conditionalexpectation">Conditional Expectation</h2>
<p>  조건이 들어간 상태에서 기대값이 어떻게 변하는지를 알아보자. 전제조건은 $ P(A) &gt; 0 $이다.</p>
<p>$$ E[X\vert A] = \displaystyle \sum_x xp_{X\vert A}(x\vert A) $$</p>
<p> $ X $ 대신 함수인 $ g(X) $가 들어가도 큰 차이 없이,</p>
<p>$$ E[g(X)\vert A] = \displaystyle \sum_x g(x)p_{X\vert A}(x\vert A) $$</p>
<p>이고, $ A $ 대신 $\{Y=y\} $라면</p>
<p>$$ E[X\vert Y=y] = \displaystyle \sum_x xp_{X\vert Y}(x\vert y) $$</p>
<p>로 기대값을 구할 수 있다.</p>
<h3 id="totalexpectationtheorem">Total Expectation Theorem</h3>
<p>  Total Probability Theorem의 기대값 버전이라고 생각하면 된다. 기본적인 개념은 모든 $ Y $ 값과 알고자하는 $ X $ 값에 대한 조건부 기대값들을 다시 평균 내는 것이다.</p>
<p>$$ E[X] = \displaystyle \sum_y p_Y(y)E[X\vert Y=y] $$</p>
]]></content:encoded></item><item><title><![CDATA[2.4 Expectation, Mean, and Variance & 2.5 Joint PMFs of Multiple]]></title><description><![CDATA[<h1 id="expectationmeanandvariance">Expectation, Mean, and Variance</h1>
<p>  여기서는 예전에 설명했던 Random Variable의 종류들에 대한 Expectation과 Variance가 어떻게 되는지만 간단하게 말해줄 것이다. 단, 증명은 단순히 전개하면 알 수 있으므로 생략한다.</p>
<h2 id="expectationsofstandardrandomvariables">Expectations of Standard Random Variables</h2>
<ul>
<li>
<p><strong>Discrete Uniform</strong> on $ {a, a + 1, \dots, b} $</p>
<p>$$ E[X] = \frac{a+b}{2} $$</p>
</li>
<li>
<p><strong>Bernoulli</strong></p>
<p>$$ E[X] = (1-p)\cdot</p></li></ul>]]></description><link>http://localhost:2368/2-4-expectation-mean-and-variance-2-5-joint-pmfs-of-multiple/</link><guid isPermaLink="false">5c35ff612d91b6c511315537</guid><category><![CDATA[probability-and-statistics]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Sat, 15 Dec 2018 05:16:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/bayesian-2889576_1280.png" medium="image"/><content:encoded><![CDATA[<h1 id="expectationmeanandvariance">Expectation, Mean, and Variance</h1>
<img src="http://localhost:2368/content/images/2019/01/bayesian-2889576_1280.png" alt="2.4 Expectation, Mean, and Variance & 2.5 Joint PMFs of Multiple"><p>  여기서는 예전에 설명했던 Random Variable의 종류들에 대한 Expectation과 Variance가 어떻게 되는지만 간단하게 말해줄 것이다. 단, 증명은 단순히 전개하면 알 수 있으므로 생략한다.</p>
<h2 id="expectationsofstandardrandomvariables">Expectations of Standard Random Variables</h2>
<ul>
<li>
<p><strong>Discrete Uniform</strong> on $ {a, a + 1, \dots, b} $</p>
<p>$$ E[X] = \frac{a+b}{2} $$</p>
</li>
<li>
<p><strong>Bernoulli</strong></p>
<p>$$ E[X] = (1-p)\cdot 0 + p\cdot 1 = p $$</p>
</li>
<li>
<p><strong>Binomial</strong></p>
<p>$$ E[X] = \sum^{n}_{k=0} k\cdot {n \choose k} p^k (1-p)^{n-k} = np $$</p>
</li>
<li>
<p><strong>Geometric</strong></p>
<p>$$ E[X] = \sum^{\infty}_{k=1}k\cdot (1-p)^{k-1}p = \frac{1}{p} $$</p>
</li>
<li>
<p><strong>Poisson</strong></p>
<p>$$E[X] = \sum^{\infty}_{k=0} k\cdot \frac{e^{-\lambda}}{k!} = \lambda $$</p>
</li>
</ul>
<h2 id="variancesofstandardrandomvariables">Variances of Standard Random Variables</h2>
<ul>
<li>
<p><strong>Discrete Uniform</strong> on $ {a, a + 1, \dots, b} $</p>
<p>$$var(X) = \frac{(b-a+1)^2 - 1}{12}$$</p>
</li>
<li>
<p><strong>Bernoulli</strong></p>
<p>$$ var(X) = p(1-p) $$</p>
</li>
<li>
<p><strong>Binomial</strong></p>
<p>$$ var(X) =  np(1-p) $$</p>
</li>
<li>
<p><strong>Geometric</strong></p>
<p>$$var(X) = \frac{1-p}{p^2}$$</p>
</li>
<li>
<p><strong>Poisson</strong></p>
<p>$$var(X) = \lambda $$</p>
</li>
</ul>
<h1 id="jointpmfsofmultiplerandomvariables">Joint PMFs of Multiple Random Variables</h1>
<h2 id="jointpmf">Joint PMF</h2>
<p>두 개의 Discrete Random Variable $ X, Y $가 같은 시행에 연관되어 있을 때, Joint PMF는 다음과 같이 정의될 수 있다.</p>
<p>$$ p_{X,Y}(x,y) = P(X=x, Y=y) $$</p>
<p>  $P(X=x, Y=y) $는 $P(X=x\ and\ Y=y) $나 $P(\{X=x\} \cap \{Y=y\}) $와 같은 뜻이다.</p>
<p>  Joint PMF는 하나의 시행에서 여러 속성을 통해 결과를 표현할 때 유용하다. 예를 들어 $ X $는 키,  $ Y $는 성적으로 두고 학생을 랜덤하게 뽑는 경우를 $ P(X=160, Y=80) $과 같이 표현할 수 있다.</p>
<h2 id="marginalpmf">Marginal PMF</h2>
<p>  Joint PMF $ p_{X, Y}(x, y) $에서 각각의 랜덤 변수 $X, Y$에 대한 PMF를 뽑아내면 그것을 Marginal PMF라 부르고 다음과 같이 구할 수 있다.</p>
<p>$$ p_X(x) = \displaystyle \sum_y p_{X,Y}(x,y) $$</p>
<p>$$ p_Y(y) = \displaystyle \sum_x p_{X,Y}(x,y) $$</p>
<p>  어떤 $ x $ 또는 $ y $에 대해 나머지 랜덤 변수의 모든 경우 확률의 합이다.</p>
<h2 id="functionsofmultiplerandomvariables">Functions of Multiple Random Variables</h2>
<p>  여기서는 이전 포스팅의 $ E[g(X)] = \displaystyle \sum_x g(x)p_X(x) $를 Joint PMF에 대한 것으로 확장한 것이다. 형태는 같고 단지 랜덤 변수 $ Y $ 가 추가되었을 뿐이다. 아래는 확장된 식이다.</p>
<p>$$ E[g(X, Y)] = \displaystyle \sum_{x, y} g(x, y)p_{X, Y}(x, y) $$</p>
<p>  $ g(X, Y) = aX+bY+c $인  경우, $ E[g(X, Y)] $는 지난 번에 이야기한 선형성에 의해 다음과 같다.</p>
<p>$$ E[g(X, Y)] = aE[X] + bE[Y] + c $$</p>
]]></content:encoded></item><item><title><![CDATA[2.3 Functions of Random Variables & 2.4 Expectation, Mean, and Variance]]></title><description><![CDATA[<h1 id="functionsofrandomvariables">Functions of Random Variables</h1>
<p>  여기서는 Random Variable이 값이 아닌 함수로 정의되는 경우에 대해 이야기한다.</p>
<p>Random Variable $ X $와 $ f : \mathbb{R} \rightarrow \mathbb{R} $인 함수 $ f $가 있다고 하자. 그리고 새로운 Random Variable $ Y $를 다음과 같이 정의할 수 있다.</p>
<p>$$ Y = f(X) $$</p>
<p>  이런 $ Y $의 PMF는 아래와 같다.</p>]]></description><link>http://localhost:2368/2-3-functions-of-random-variables-2-4-expectation-mean-and-variance/</link><guid isPermaLink="false">5c36000e2d91b6c511315549</guid><category><![CDATA[probability-and-statistics]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Sat, 15 Dec 2018 04:30:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/graphic-1606688_1280.png" medium="image"/><content:encoded><![CDATA[<h1 id="functionsofrandomvariables">Functions of Random Variables</h1>
<img src="http://localhost:2368/content/images/2019/01/graphic-1606688_1280.png" alt="2.3 Functions of Random Variables & 2.4 Expectation, Mean, and Variance"><p>  여기서는 Random Variable이 값이 아닌 함수로 정의되는 경우에 대해 이야기한다.</p>
<p>Random Variable $ X $와 $ f : \mathbb{R} \rightarrow \mathbb{R} $인 함수 $ f $가 있다고 하자. 그리고 새로운 Random Variable $ Y $를 다음과 같이 정의할 수 있다.</p>
<p>$$ Y = f(X) $$</p>
<p>  이런 $ Y $의 PMF는 아래와 같다.</p>
<p>$$ P(Y=k) = P(f(X) = k) = \sum_{o\in \Omega\ such\ that\ f(X(o))=k}P(o) $$</p>
<p> 풀어서 설명하면 $ {Y=k} $의 확률은 $ f(X)=k $가 되게하는 outcome $ o $들의 확률을 더한 것이다.</p>
<h1 id="expectationmeanandvariance">Expectation, Mean, and Variance</h1>
<h2 id="expectedvalue">Expected Value</h2>
<p>  Expected Value, 기대값은 Random Variable $ X $에 대해 다음과 같이 정의된다.</p>
<p>$$ E[X] = \displaystyle \sum_{x\in \mathbb{R}} xP(X=x) $$</p>
<p>이 값은 $X$ 값에 대한 확률을 고려한 평균이라고 할 수 있다. $ E[X] $는 Expectation 또는 Mean이라고도 불린다.</p>
<h3 id="linearityofexpectation">Linearity of Expectation</h3>
<p>  Expectation은 선형성이라는 특성을 가지고 있다. 고등학교 때 들어본 경험이 있을 수도 있는데 아래 식과 같은 특성을 가진 것을 선형성이 있다고 한다.</p>
<p>$$ E[X + Y] = E[X] + E[Y] $$</p>
<p>$$ E[aX] = aE[X] $$</p>
<h2 id="variance">Variance</h2>
<p>  우리가 분산이라고 부르는 Variance는 평균으로부터 얼마나 떨어져 있는지를 계산한 값이다. 이는 모든 $X$에 대해 $ (X-E[X])^2 $ 를 구한 다음 평균을 내서 구한다. 아래에 식으로 정리되어 있다.</p>
<p>$$ var(X) = E[(X-E[X])^2] = \sum(k-E[X])^2 P(X=k) $$</p>
<p>Variance를 정리하면 아래 식과도 같다.</p>
<p>$$ var(X) = E[X^2] - E[X]^2 $$</p>
<p>  고등학교 때 '제평평제' 등으로 외웠던 식이다.</p>
<p>그리고 분산으로부터 <em>표준편차</em>도 구할 수 있는데, 분산에 루트를 씌우면 된다.</p>
<p>$$ \sigma_x = std(X) = \sqrt{var(X)} $$</p>
<h2 id="expectedvalueruleforfunctionsofrandomvariable">Expected Value Rule for Functions of Random Variable</h2>
<p>  앞서 Random Variable이 함수로 정의될 수도 있다고 했다. 여기서는 Random Variable 함수의 Expectation을 구하는 식을 소개한다. $ g(X) $는 Random Variable을 실수로 매핑하는 함수이다. 이 함수의 기대값은 아래와 같다.</p>
<p>$$ E[g(X)] = \displaystyle \sum_x g(x)p_X(x) $$</p>
<h2 id="meanandvarianceofalinearfunctionofarandomvariable">Mean and Variance of a Linear Function of a Random Variable</h2>
<p>  Random Variable이 선형 함수 형태일 때, Expectation과 Variance는 어떻게 변할까? 선형 함수를 일반화한 Random Variable $ Y=aX+b $를 기준으로 다음과 같다.</p>
<p>$$ E[Y] = aE[X]+b $$</p>
<p>$$ var(Y) = a^2var(X) $$</p>
<p>Expectation은 앞에서 말한 선형성 때문임을 알 수 있고, Variance는 전개를 직접해서 왜 그런지 증명해보자. 그러면 다음부턴 당연하게 여겨질 것이다.</p>
]]></content:encoded></item><item><title><![CDATA[2.1 Basic Concepts & 2.2 Probability Mass Function]]></title><description><![CDATA[<p>  2장의 전체적인 내용은 Discrete Random Variable에 관한 것이다. 이 포스팅에서는 Random Variable과 Probability Mass Function(PMF)이 무엇인지에 대해 설명한다.</p>
<h1 id="basicconcepts">Basic Concepts</h1>
<h2 id="randomvariable">Random Variable</h2>
<p>  정의를 그대로 읽어보자면, Random Variable이란 Sample Space를 실수에 매핑하는 함수이다. 다시 말해 입력은 outcome, 출력은 실수인 함수이다. 아직은 말이 어렵다. 예제를 통해 알아보자.</p>
<h3 id="example">Example</h3>
<p>  4면을 가지고(</p>]]></description><link>http://localhost:2368/2-1-basic-concepts-2-2-probability-mass-function/</link><guid isPermaLink="false">5c3600a72d91b6c511315559</guid><category><![CDATA[probability-and-statistics]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Sat, 15 Dec 2018 03:45:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/preview.jpg" medium="image"/><content:encoded><![CDATA[<img src="http://localhost:2368/content/images/2019/01/preview.jpg" alt="2.1 Basic Concepts & 2.2 Probability Mass Function"><p>  2장의 전체적인 내용은 Discrete Random Variable에 관한 것이다. 이 포스팅에서는 Random Variable과 Probability Mass Function(PMF)이 무엇인지에 대해 설명한다.</p>
<h1 id="basicconcepts">Basic Concepts</h1>
<h2 id="randomvariable">Random Variable</h2>
<p>  정의를 그대로 읽어보자면, Random Variable이란 Sample Space를 실수에 매핑하는 함수이다. 다시 말해 입력은 outcome, 출력은 실수인 함수이다. 아직은 말이 어렵다. 예제를 통해 알아보자.</p>
<h3 id="example">Example</h3>
<p>  4면을 가지고(각 면의 숫자는 1, 2, 3, 4) 모든 면이 나올 확률이 동일한 두 개의 주사위가 있다. 두 주사위를 동시에 던졌을 때 나오는 숫자쌍을 $ o\in{\Omega}, o = (o_1, o_2) $라 하자. 이를 바탕으로 $ X(o_1, o_2) = max(o_1, o_2) $로 정의된 함수를 생각해볼 수 있다. 이 때 $X$는 Sample Space의 $o$를 실수인 $ o_1, o_2 $ 중 하나로 매핑하는 것으로 볼 수 있으므로 Random Variable인 것이다.</p>
<h2 id="randomvariablesgiveaneasywaytospecifyevents">Random Variables Give An Easy Way to Specify Events</h2>
<p>  랜덤 변수를 사용하면 어떤 Event를 아주 단순하게 지칭할 수 있게 된다. $ X : \Omega \rightarrow \mathbb{R} $ 인 함수(or Random Variable)가 있을 때 다음과 같이 Event를 표현할 수 있다.</p>
<p>$$ {X = x} = {o \vert o \in \Omega\ and\ X(o) = x} $$</p>
<p>  즉, $X$가 $x$가 되게하는 Event를 $ X=x $라는 것으로 표현할 수 있다는 것이다. 주사위 예제에서 한 번 적용해보자면, $ {(1,2), (2,1), (2,2)} $ 라는 Event를 표현하기 위해서 $ {X=2} $라고 단순하게 적을 수 있게 된 것이다. 2라는 숫자가 함수 $X$에 의해 $ {(1,2), (2,1), (2,2)} $와 매핑되었기 때문에 가능해졌다.</p>
<h2 id="randomvariablesandprobability">Random Variables and Probability</h2>
<p> 확률을 표현할 때도 Random Variable을 사용하면 편리하다. 주사위 예제를 계속 활용하여 설명하겠다. Random Variable을 사용하면 $ (1,2), (2,1), (2,2) $ 다음 세 outcome의 확률을 더한 값을 알고 싶을 때 $ P(X=2) $라고만 쓰면 된다.</p>
<h1 id="probabilitymassfunctionpmf">Probability Mass Function(PMF)</h1>
<p>  Probability Mass Function이란 ${X=x}$의 확률에 대한 함수이다. 즉 입력은 Random Variable 값이고 출력은 확률으로 가지는 함수인 것이다. 바로 앞 주제에서 본 형태인 $ P(X=x) $ 또는 간단하게 $ p_X(x) $로 나타낸다.</p>
<h1 id="randomvariable">Random Variable의 종류</h1>
<p>  Random Variable은 우리가 임의로 정의할 수 있지만, 많은 상황에서 적용할 수 있는 대표적인 Random Variable의 종류를 소개하겠다.</p>
<h2 id="discreteuniformrandomvariables">Discrete Uniform Random Variables</h2>
<p>  특정 범위(a와 b 사이)의 Random Variable 값이 같은 확률을 가지는 경우이다. 그래서 Discrete Uniform Random Variable의 PMF는 아래와 같다.</p>
<p>$$ p_X(k) = P(X = k) =  \begin{cases}<br>
\frac{1}{b-a-1}\ if\ k=a, a+1, \cdots, b\\<br>
0\ if\ otherwise<br>
\end{cases} $$</p>
<p>$ \frac{1}{b-a-1} $은 a와 b 사이의 정수들이 가지는 동일한 확률이다.</p>
<h2 id="bernoullirandomvariables">Bernoulli Random Variables</h2>
<p>  베르누이 랜덤 변수는 값을 두 개만 가진다. 동전 토스 같이 두 가지 outcome만 있는 상황에서 사용된다. PMF는 다음과 같다.($X$는 0 또는 1)</p>
<p>$$ p_X(k) = P(X=k) = \begin{cases} p\ \ \ \ \ \ \ \ \ \ \ if\ k=1 \\ 1-p\ \ \ \ if\ k=0 \end{cases} $$</p>
<h2 id="binomialrandomvariables">Binomial Random Variables</h2>
<p>  성공 / 실패가 있는 상황이 n번 시행되었을 때 성공한 횟수를 $ X $의 값으로 가지는 Random Variable이다. 한 번의 시행에서 성공할 확률을 $ p $라고 하자. PMF는 우리가 흔히 아는 형태로 다음과 같다.</p>
<p>$$ p_X(k) = P(X=k) = {n \choose k} p^k (1-p)^{n-k}\ (k=0, 1, \dots, n) $$</p>
<h2 id="geometricrandomvariables">Geometric Random Variables</h2>
<p>  몇 번째 시행에서 처음 성공했는지를 $ X $의 값으로 가진다. $ X = k $라 하면, 첫 번째부터 k-1 번째 시행은 전부 실패하고 k 번째에서 성공했다는 뜻이다. 한 번의 시행에 대해 성공할 확률을 $ p $라고 하면, PMF는 다음과 같다.</p>
<p>$$ p_X(x) = P(X=k) = (1-p)^{k-1}p $$</p>
<h2 id="poissonrandomvariables">Poisson Random Variables</h2>
<p>  Binomial Random Variable에서 n이 매우 크고 p가 매우 작은 상황에서는 연산 비용이 매우 커진다. Poisson Random Variable은 이러한 상황에서 적용할 수 있는 Binomial Random Variable의 PMF를 근사시켜 연산 비용을 줄인 PMF를 가지고 있다. 따라서 기본적인 상황 개념과 X의 값은 Binomial과 동일하다. 아래는 PMF인데, 여기서 $ \lambda = np $이다.</p>
<p>$$ p_X(k) = p(X=k) = e^{-\lambda}\frac{\lambda^{k}}{k!} \approx  {n \choose k} p^k (1-p)^{n-k}$$</p>
<!--Image Credit(Freepik) -->
<a style="font-family:sans-serif; font-size: 15px; color: #26a8ed;
    text-decoration: none; box-shadow: none;" href="https://www.freepik.com/free-photos-vectors/background">Header Image created by Freepik</a>]]></content:encoded></item><item><title><![CDATA[4.14 Fallacies and Pitfalls]]></title><description><![CDATA[<h1 id="fallaciesandpitfalls">Fallacies and Pitfalls</h1>
<h2 id="fallacypipelineiseasy">Fallacy: Pipeline is easy</h2>
<p>  지금까지 파이프라인을 잘 이해한 사람들은 어쩌면 이것이 별 거 아니라고 생각할 수도 있다. 그렇지만 지금까지 다룬 것은 파이프라인의 기본적인 개념이고, 더 세부적인 것을 고려하기 시작하면 만만치 않을 것이다.</p>
<p>  파이프라인의 어려움에 대한 이야기를 말하자면, 이 강의 교재의 1st Edition에서 나온 파이프라인에 버그가 있었는데 이</p>]]></description><link>http://localhost:2368/4-14-fallacies-and-pitfalls/</link><guid isPermaLink="false">5c35fb602d91b6c5113154dd</guid><category><![CDATA[computer-architecture]]></category><dc:creator><![CDATA[Wonjun Shin]]></dc:creator><pubDate>Fri, 14 Dec 2018 13:50:00 GMT</pubDate><media:content url="http://localhost:2368/content/images/2019/01/14231.jpg" medium="image"/><content:encoded><![CDATA[<h1 id="fallaciesandpitfalls">Fallacies and Pitfalls</h1>
<h2 id="fallacypipelineiseasy">Fallacy: Pipeline is easy</h2>
<img src="http://localhost:2368/content/images/2019/01/14231.jpg" alt="4.14 Fallacies and Pitfalls"><p>  지금까지 파이프라인을 잘 이해한 사람들은 어쩌면 이것이 별 거 아니라고 생각할 수도 있다. 그렇지만 지금까지 다룬 것은 파이프라인의 기본적인 개념이고, 더 세부적인 것을 고려하기 시작하면 만만치 않을 것이다.</p>
<p>  파이프라인의 어려움에 대한 이야기를 말하자면, 이 강의 교재의 1st Edition에서 나온 파이프라인에 버그가 있었는데 이 버그는 100명 이상이 검토하고 18개 대학에서 시험을 칠 동안 발견되지 않았다. 어떤 사람이 이 책을 바탕으로 컴퓨터를 만드려고 시도하다가 그제서야 이 버그가 발견되었다고 한다.</p>
<h2 id="fallacypipeliningcanbeimplementedindependentoftechnology">Fallacy: Pipelining can be implemented independent of technology</h2>
<p>  위 문장은 한국어로 &quot;파이프라인은 기술과 상관 없이 구현 가능하다&quot;는 착각인데 그렇지 않다. 칩에 들어가는 트랜지스터가 많아질수록 더 발전된 파이프라인을 만들 수 있으며, 파이프라인과 관련된 ISA 설계는 많은 기술 트렌드를 필요로 한다.</p>
<h2 id="pitfallfailuretoconsiderinstructionsetdesigncanadverselyimpactpipelining">Pitfall: Failure to consider instruction set design can adversely impact pipelining</h2>
<p>  파이프라이닝을 하기에 얼마나 힘든지는 Instruction Set의 설계를 잘했는지 보다는 얼마나 복잡한 Instruction Set인지에 영향을 많이 받는다. 복잡한 Instruction들은 파이프라이닝을 구현하기 위해서 상당한 오버헤드가 존재하기 때문이다.</p>
<!--Image Credit(Freepik) -->
<a style="font-family:sans-serif; font-size: 15px; color: #26a8ed;
    text-decoration: none; box-shadow: none;" href="https://www.freepik.com/free-photos-vectors/background">Header Image created by Freepik</a>]]></content:encoded></item></channel></rss>